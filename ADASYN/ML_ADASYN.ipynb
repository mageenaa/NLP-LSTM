{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWK-Ezh1HKDg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "teks = pd.read_excel(\"text.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqHIM0s-IVUL"
      },
      "outputs": [],
      "source": [
        "teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjPNo8xAJElU"
      },
      "outputs": [],
      "source": [
        "teks.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cuNP-1WIg3E"
      },
      "outputs": [],
      "source": [
        "teks.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyH8A03UIj3r"
      },
      "outputs": [],
      "source": [
        "teks['Kalimat'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz_6pgoLIzIx"
      },
      "outputs": [],
      "source": [
        "teks['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZmgRtvZJB70"
      },
      "outputs": [],
      "source": [
        "teks['length_before_cleaning'] = teks['Text'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRgni6G7JOTX"
      },
      "outputs": [],
      "source": [
        "teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abBg9b3UD5s5"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import nltk #import library Natural Language Toolkit\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRMjihY6D9Fa"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gKUZNTgKY56"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQz9iFG3KrF1"
      },
      "outputs": [],
      "source": [
        "#Lemmatisasi Text\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#tokenisasi text\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL7iM8vvOrlh"
      },
      "outputs": [],
      "source": [
        "# Download WordNet resource\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tljReFZuK7f3"
      },
      "outputs": [],
      "source": [
        "#reguler python (RegEx)\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBwULvs_LHMv"
      },
      "outputs": [],
      "source": [
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "teks['Text'] = teks['Text'].apply(lambda x: convert_to_lower(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20xwO-prMfnU"
      },
      "outputs": [],
      "source": [
        "def remove_numbers(text):\n",
        "    number_pattern = r'\\d+'\n",
        "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "    return without_number\n",
        "\n",
        "teks['Text'] = teks['Text'].apply(lambda x: remove_numbers(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3zzFVxGMr4E"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "teks['Text'] = teks['Text'].apply(lambda x: remove_punctuation(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK0hKiNvMotf"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "def remove_stopwords(text):\n",
        "    removed = []\n",
        "    stop_words = list(stopwords.words(\"english\"))\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        if tokens[i] not in stop_words:\n",
        "            removed.append(tokens[i])\n",
        "    return \" \".join(removed)\n",
        "teks['Text'] = teks['Text'].apply(lambda x: remove_punctuation(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEQKc2l8N8R3"
      },
      "outputs": [],
      "source": [
        "def remove_extra_white_spaces(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_sc\n",
        "teks['Text'] = teks['Text'].apply(lambda x: remove_extra_white_spaces(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXY9Z3OvOEW3"
      },
      "outputs": [],
      "source": [
        "def lemmatizing(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
        "        tokens[i] = lemma_word\n",
        "    return \" \".join(tokens)\n",
        "teks['Text'] = teks['Text'].apply(lambda x: lemmatizing(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ig9SPKZOyBP"
      },
      "outputs": [],
      "source": [
        "teks['length_after_cleaning'] = teks['Text'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LFgCGrvO5a4"
      },
      "outputs": [],
      "source": [
        "teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlyLgBIR-TXK"
      },
      "outputs": [],
      "source": [
        "teks.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVqB7VAN_hxV"
      },
      "outputs": [],
      "source": [
        "# Menghapus kolom 'Kota' dan mengubah dataframe asli\n",
        "teks.drop('Kalimat', axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eff8G02SDhlz"
      },
      "outputs": [],
      "source": [
        "label_map = {\n",
        "    'supports': 0,\n",
        "    'attacks': 1,\n",
        "}\n",
        "\n",
        "teks['Label'] = teks['Label'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7nOPCrZANoK"
      },
      "outputs": [],
      "source": [
        "teks.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSPy9ssnrg7x"
      },
      "outputs": [],
      "source": [
        "teks_lstm = teks.copy()\n",
        "teks_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo9zYMHCKoDB"
      },
      "outputs": [],
      "source": [
        "# Pisahkan fitur dan label\n",
        "X = teks['Text'] #fitur\n",
        "y = teks['Label'] #target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RMu1Ng1vQef"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Inisialisasi vektorisasi teks (TF-IDF)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkwEtDHDMd-s"
      },
      "source": [
        "**Dataset Balancing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NOUzkUNtpif"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "ADA = ADASYN(random_state=130)\n",
        "X_train_ADA, y_train_ADA = ADA.fit_resample(X_tfidf, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvebdzuGvY_g"
      },
      "outputs": [],
      "source": [
        "# from imblearn.over_sampling import SMOTE\n",
        "# # Inisialisasi SMOTE\n",
        "# smote = SMOTE(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAVLhR_uuHWF"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "print(Counter(y_train_ADA))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poUVLLyKMTem"
      },
      "source": [
        "**SPLIT DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_xkQ-ldCaBt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Bagi dataset menjadi data pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_ADA, y_train_ADA, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo9hhuqfm7HB"
      },
      "source": [
        "**NAIVE BAYES MULTINOMIAL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NKtrBSsnDbg"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWMLoCaIm-tP"
      },
      "outputs": [],
      "source": [
        "# Inisialisasi model Naive Bayes Multinomial\n",
        "NBM = MultinomialNB()\n",
        "# Pelatihan model\n",
        "NBM.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl61YNAqnFmp"
      },
      "outputs": [],
      "source": [
        "# Evaluasi model pada data pengujian\n",
        "y_pred_nb = NBM.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Akurasi Naive Bayes Multinomial:\", accuracy_score(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmYDcOTsnAag"
      },
      "outputs": [],
      "source": [
        "print(\"Naive Bayes Multinomial Classification Report:\\n\", classification_report(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAcCyRa4nJ-Q"
      },
      "source": [
        "**SUPPORT VECTOR CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftLhxyG4nIQU"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4-55yytnO4D"
      },
      "outputs": [],
      "source": [
        "# Inisialisasi model SVM\n",
        "svc_model = SVC(kernel='linear')\n",
        "# Pelatihan model\n",
        "svc_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALe2WGG6nUys"
      },
      "outputs": [],
      "source": [
        "# Evaluasi model pada data pengujian\n",
        "y_pred_svc = svc_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Akurasi SVC:\", accuracy_score(y_test, y_pred_svc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PRcRSnDnXpq"
      },
      "outputs": [],
      "source": [
        "print(\"SVC Classification Report:\\n\", classification_report(y_test, y_pred_svc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6S8Ph1Qnbf6"
      },
      "source": [
        "**RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xapN4eX8nYfe"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z3DXbBmngjT"
      },
      "outputs": [],
      "source": [
        "# Inisialisasi model Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# Pelatihan model\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifRhbYmjnhum"
      },
      "outputs": [],
      "source": [
        "# Evaluasi model pada data pengujian\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Akurasi Random Forest:\", accuracy_score(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eO-63xtnkbC"
      },
      "outputs": [],
      "source": [
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CIEaAtIXqZm"
      },
      "source": [
        "**K-Nearest Neighbors (KNN)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-eRFHKYXvNo"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uoav7JEXX4Fc"
      },
      "outputs": [],
      "source": [
        "k = 3  # Jumlah tetangga yang akan digunakan\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "knn_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inmHE0S7X9pC"
      },
      "outputs": [],
      "source": [
        "y_pred_knn = knn_classifier.predict(X_test)\n",
        "\n",
        "# Mengukur kinerja model\n",
        "print(\"Akurasi KNN:\", accuracy_score(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IctO_YJgYrA7"
      },
      "outputs": [],
      "source": [
        "print(\"KNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYvOiYhPZLjM"
      },
      "source": [
        "**XGBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mfly-etJY3FS"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oTx62ipZdzy"
      },
      "outputs": [],
      "source": [
        "xgb = xgb.XGBClassifier(\n",
        "    objective=\"binary:logistic\",  # Klasifikasi biner\n",
        "    max_depth=3,                  # Kedalaman maksimum pohon\n",
        "    learning_rate=0.1,            # Tingkat pembelajaran\n",
        "    n_estimators=100              # Jumlah iterasi (pohon) atau estimator\n",
        ")\n",
        "xgb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEesHZzFarY6"
      },
      "outputs": [],
      "source": [
        "y_pred_xgb = xgb.predict(X_test)\n",
        "# Mengukur kinerja model\n",
        "print(\"Akurasi XGBoost:\", accuracy_score(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu6vTdzcbLb1"
      },
      "outputs": [],
      "source": [
        "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNk4JNLynk9e"
      },
      "source": [
        "**LSTM (LONG SHORT TERM MEMORY) + TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg0jE2niezu5"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "# from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9ea7akisCYi"
      },
      "outputs": [],
      "source": [
        "# teks_lstm = teks.copy()\n",
        "# teks_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzr78aS0qYLd"
      },
      "outputs": [],
      "source": [
        "# # Pisahkan fitur dan label\n",
        "# X = teks_lstm['Text'] #fitur\n",
        "# y = teks_lstm['Label'] #target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G4Js-1Dsg8x"
      },
      "outputs": [],
      "source": [
        "# # Tokenisasi\n",
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(X)\n",
        "\n",
        "# X_sequences = tokenizer.texts_to_sequences(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_3s2fXysidv"
      },
      "outputs": [],
      "source": [
        "# max_seq_length = 100\n",
        "# X_padded = pad_sequences(X_sequences, maxlen=max_seq_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiukGXCJs2eu"
      },
      "outputs": [],
      "source": [
        "# # Balancing dataset menggunakan ADASYN\n",
        "# ADASYN= ADASYN(random_state=42)\n",
        "# X_ADA, y_ADA = ADASYN.fit_resample(X_padded, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i7tTJJKtL8Y"
      },
      "outputs": [],
      "source": [
        "# # model LSTM\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_seq_length))\n",
        "# model.add(SpatialDropout1D(0.4))\n",
        "# model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
        "# model.add(Dense(2, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7ka3O77tULd"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEm2q7pOtU2B"
      },
      "outputs": [],
      "source": [
        "# # Melatih model pada seluruh dataset\n",
        "# model.fit(X_ADA, y_ADA, epochs=10, batch_size=64, validation_data=(X_ADA, y_ADA))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
